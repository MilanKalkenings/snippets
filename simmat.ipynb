{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\milan\\OneDrive\\Documents\\portfolio\\entity_resolution\\.venv\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import KMeans\n",
    "import difflib\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simmat:\n",
    "    def __init__(self, sim_object):\n",
    "        self.mat = np.array([], dtype=float)\n",
    "        self.nodes = []\n",
    "        self.sim_object = sim_object\n",
    "\n",
    "    def add_node(self, node: str, compare_to_ids: List[int] = None):\n",
    "        \"\"\"\n",
    "        compare_to_ids: only compare <node> to respective other nodes,\n",
    "        useful for blocking\n",
    "        \"\"\"\n",
    "        assert node not in self.nodes, \"node already exists\"\n",
    "        if compare_to_ids is None:\n",
    "            compare_to_ids = range(len(self.nodes))\n",
    "        self.nodes.append(node)\n",
    "        node_sims = np.zeros(len(self.nodes), dtype=float)\n",
    "        for i in compare_to_ids:\n",
    "            node_other = self.nodes[i]\n",
    "            node_sims[i] = self.sim_object.sim(node, node_other)\n",
    "        if tuple(self.mat.shape) == (0,):\n",
    "            self.mat = np.array([1], dtype=float).reshape(1, 1)\n",
    "        else:\n",
    "            shape = self.mat.shape[0]\n",
    "            mat_new = np.zeros((shape + 1, shape + 1))\n",
    "            mat_new[:shape, :shape] = self.mat\n",
    "            mat_new[-1, :] = node_sims\n",
    "            mat_new[:, -1] = node_sims\n",
    "            self.mat = mat_new\n",
    "\n",
    "    def remove_node(self, node: str):\n",
    "        node_id = self.nodes.index(node)\n",
    "        self.nodes.remove(node)\n",
    "        self.mat = np.delete(self.mat, node_id, axis=0)\n",
    "        self.mat = np.delete(self.mat, node_id, axis=1)\n",
    "\n",
    "\n",
    "class CharNgramBlock:\n",
    "    def __init__(\n",
    "            self, \n",
    "            n: int = 3, \n",
    "            chars: str = 'abcdefghijklmnopqrstuvwxyzäöüß.-_1234567890 '):\n",
    "        self.vocabulary = [''.join(triple) for triple in itertools.product(chars, repeat=n)]\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            #vocabulary=self.vocabulary, \n",
    "            analyzer=lambda text: self.char_ngrams(text, n))\n",
    "\n",
    "    @staticmethod\n",
    "    def char_ngrams(node: str, n: int) -> list[str]:\n",
    "        return [node[i:i+n] for i in range(len(node)-n+1)]\n",
    "\n",
    "    def block(self, nodes: pd.Series, n_blocks: int) -> List[List[int]]:\n",
    "        tfidf_matrix = self.vectorizer.fit_transform(nodes)\n",
    "        preds = KMeans(n_clusters=n_blocks, n_init=10).fit_predict(tfidf_matrix)\n",
    "        value_to_ids = defaultdict(list)\n",
    "        for idx, value in enumerate(preds):\n",
    "            value_to_ids[value].append(idx)\n",
    "        return dict(value_to_ids), preds\n",
    "\n",
    "\n",
    "class CharNgramSim:\n",
    "    def __init__(\n",
    "            self, \n",
    "            n: int = 3, \n",
    "            chars: str = 'abcdefghijklmnopqrstuvwxyzäöüß.-_1234567890 ', \n",
    "            precision: int = 2):\n",
    "        self.precision = precision\n",
    "        self.vocabulary = [''.join(triple) for triple in itertools.product(chars, repeat=n)]\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            vocabulary=self.vocabulary, \n",
    "            binary=True, \n",
    "            use_idf=False, \n",
    "            norm=None, \n",
    "            analyzer=lambda text: self.char_ngrams(text, n))\n",
    "        self.vectorizer.fit([\"text\"])\n",
    "\n",
    "    @staticmethod\n",
    "    def char_ngrams(node: str, n: int) -> list[str]:\n",
    "        return [node[i:i+n] for i in range(len(node)-n+1)]\n",
    "    \n",
    "    def sim(self, node_i: str, node_j: str) -> int:\n",
    "        vector1, vector2 = self.vectorizer.transform([node_i, node_j])\n",
    "        return round(1 - (np.abs(vector1.todense() - vector2.todense()).sum() / (vector1.sum() + vector2.sum())), self.precision)\n",
    "\n",
    "\n",
    "class EditSim:\n",
    "    def __init__(\n",
    "            self, \n",
    "            precision: int = 2):\n",
    "        self.precision = precision\n",
    "\n",
    "    @staticmethod\n",
    "    def char_ngrams(node: str, n: int) -> list[str]:\n",
    "        return [node[i:i+n] for i in range(len(node)-n+1)]\n",
    "    \n",
    "    def sim(self, node_i: str, node_j: str) -> int:\n",
    "        return round(1 - difflib.SequenceMatcher(None, node_i, node_j).ratio(), self.precision)\n",
    " \n",
    "\n",
    "class EditPartialSim:\n",
    "    def __init__(\n",
    "            self, \n",
    "            precision: int = 2):\n",
    "        self.precision = precision\n",
    "\n",
    "    @staticmethod\n",
    "    def char_ngrams(node: str, n: int) -> list[str]:\n",
    "        return [node[i:i+n] for i in range(len(node)-n+1)]\n",
    "    \n",
    "    def sim(self, node_i: str, node_j: str) -> int:\n",
    "        return round(fuzz.partial_ratio(node_i, node_j), self.precision)\n",
    "    \n",
    "\n",
    "class EditSetSim:\n",
    "    def __init__(\n",
    "            self, \n",
    "            precision: int = 2):\n",
    "        self.precision = precision\n",
    "\n",
    "    @staticmethod\n",
    "    def char_ngrams(node: str, n: int) -> list[str]:\n",
    "        return [node[i:i+n] for i in range(len(node)-n+1)]\n",
    "    \n",
    "    def sim(self, node_i: str, node_j: str) -> int:\n",
    "        return round(fuzz.token_set_ratio(node_i, node_j), self.precision)\n",
    "    \n",
    "\n",
    "class TfidfSim:\n",
    "    def __init__(\n",
    "            self,\n",
    "            nodes: List[str],\n",
    "            precision: int = 2):\n",
    "        self.vectors = TfidfVectorizer().fit_transform(nodes) \n",
    "        self.precision = precision\n",
    "        self.nodes = nodes\n",
    "\n",
    "\n",
    "    def sim(self, node_i: str, node_j: str) -> int:\n",
    "        i = self.nodes.index(node_i)\n",
    "        j = self.nodes.index(node_j)\n",
    "        return round(cosine_similarity(self.vectors[i], self.vectors[j])[0, 0], self.precision)\n",
    "\n",
    "\n",
    "class SimNet:\n",
    "    def __init__(self, nodes: List[str], sim_mat, edge_thresh: float, use_cliques: bool = False):\n",
    "        sim_mat = sim_mat * (np.triu(np.ones((len(sim_mat), len(sim_mat))), k=0)) - np.eye(N=len(sim_mat))\n",
    "        edge_ids = np.argwhere(sim_mat > edge_thresh)\n",
    "        g = nx.Graph()\n",
    "        for e in edge_ids:\n",
    "            node_i = nodes[e[0]]\n",
    "            node_j = nodes[e[1]]\n",
    "            g.add_edge(node_i, node_j, weight=sim_mat[e])\n",
    "            g.add_edge(node_j, node_i, weight=sim_mat[e])\n",
    "        for n in [n for n in range(len(nodes)) if n not in np.unique(edge_ids)]:\n",
    "            g.add_node(nodes[n])\n",
    "        self.g = g\n",
    "        if use_cliques:\n",
    "            self.cliques = list(nx.find_cliques(g))\n",
    "        components = [component for component in nx.connected_components(g)]\n",
    "        component_map = pd.DataFrame({\"node\": nodes})\n",
    "        component_map[\"component\"] = None\n",
    "        component_map[\"len\"] = None\n",
    "        self.biggest_component_size = 0\n",
    "        for i, component in enumerate(components):\n",
    "            component_map.loc[component_map[\"node\"].isin(component), \"component\"] = i\n",
    "            if len(component) > self.biggest_component_size:\n",
    "                self.biggest_component_size = len(component)\n",
    "        self.component_lengths = [len(component) for component in components]\n",
    "        self.component_map = pd.Series(component_map[\"component\"].values, index=component_map[\"node\"].values)\n",
    "\n",
    "    def sim_cn_jaccard(self, node_i: str, node_j: str, weighted: bool = False) -> float:\n",
    "        # individual neighbors\n",
    "        neighbors_i = set(self.g.neighbors(node_i))\n",
    "        neighbors_j = set(self.g.neighbors(node_j))\n",
    "        union = neighbors_i.union(neighbors_j)\n",
    "        intersection = neighbors_i.intersection(neighbors_j)\n",
    "        if weighted:\n",
    "            weights_total_i = sum([self.g.get_edge_data(node_i, n)[\"weight\"] for n in neighbors_i])\n",
    "            weights_total_j = sum([self.g.get_edge_data(node_j, n)[\"weight\"] for n in neighbors_j])\n",
    "            weights_total = weights_total_i + weights_total_j\n",
    "        else:\n",
    "            weights_total = len(union)\n",
    "        # common neighbors\n",
    "        if weighted:\n",
    "            weights_common = 0\n",
    "            for neighbor in intersection:\n",
    "                # Sum of edge weights from node_i and node_j to the common neighbor\n",
    "                weight_i = self.g[node_i][neighbor]['weight']\n",
    "                weight_j = self.g[node_j][neighbor]['weight']\n",
    "                weights_common += weight_i + weight_j\n",
    "        else:\n",
    "            weights_common = len(intersection)\n",
    "        if weights_total == 0:\n",
    "            return 0\n",
    "        return weights_common / weights_total\n",
    "    \n",
    "    def sim_clique_jaccard(self, node_i: str, node_j: str) -> float:\n",
    "        cliques_i = set([i for i, c in enumerate(self.cliques) if node_i in c])\n",
    "        cliques_j = set([i for i, c in enumerate(self.cliques) if node_j in c])\n",
    "        union = cliques_i.union(cliques_j)\n",
    "        intersection = cliques_i.intersection(cliques_j)\n",
    "        if len(union) == 0:\n",
    "            return 0\n",
    "        return len(intersection) / len(union)\n",
    "    \n",
    "    def sim_preferential_attachment(self, node_i: str, node_j: str) -> float:\n",
    "        return self.g.degree(node_i) * self.g.degree(node_j)\n",
    "    \n",
    "    def sim_component(self, node_i: str, node_j: str) -> float:\n",
    "        \"\"\"\n",
    "        if two nodes are in different components, they are unsimilar\n",
    "        if two nodes are within the same component, \n",
    "        they are likely more similar, the smaller the component\n",
    "        \"\"\"\n",
    "        if self.component_map[node_i] == self.component_map[node_j]: \n",
    "            component_len = self.component_lengths[self.component_map[node_i]]\n",
    "            return 1 - (component_len / (self.biggest_component_size + 1))\n",
    "        return 0\n",
    "    \n",
    "    def shortest_path(self, node_i: str, node_j: str) -> int:\n",
    "        try:\n",
    "            shortest_path = nx.shortest_path(self.g, source=node_i, target=node_j)\n",
    "            return len(shortest_path)\n",
    "        except nx.NetworkXNoPath:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "n = 1_000\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"data/music/musicbrainz-20000-A01.csv\")\n",
    "view = df[df[\"language\"].isin([\"German\", \"Ger.\", \"german\", \"geerman\", \"Geerman\", \"GERMAN\"])][[\"CID\", \"title\"]]\n",
    "view.dropna(inplace=True)\n",
    "view[\"title\"] = view[\"title\"].apply(lambda x: re.sub(\"\\d\\d\\d-\", \"\", x).lower())\n",
    "view = view.drop_duplicates(\"title\")\n",
    "view = view[view[\"CID\"].duplicated(keep=False)]\n",
    "view = view.sort_values(\"CID\")\n",
    "view = view.groupby(\"CID\").filter(lambda x: len(x) == 4).head(n)\n",
    "view.index = range(len(view))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     111\n",
       "18     89\n",
       "4      69\n",
       "5      68\n",
       "1      61\n",
       "12     58\n",
       "19     53\n",
       "3      51\n",
       "17     50\n",
       "0      49\n",
       "7      47\n",
       "2      43\n",
       "13     41\n",
       "15     40\n",
       "14     36\n",
       "8      36\n",
       "6      27\n",
       "16     26\n",
       "10     25\n",
       "11     20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Block = CharNgramBlock()\n",
    "block_dict, block_ids = Block.block(view[\"title\"], n_blocks=20)\n",
    "pd.Series(block_ids).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "char_ngram_sim = CharNgramSim()\n",
    "simmat_char_ngram = Simmat(sim_object=char_ngram_sim)\n",
    "for i, t in enumerate(view[\"title\"]):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    block = []\n",
    "    for j in block_dict[block_ids[i]]:\n",
    "        if j < i:\n",
    "            block.append(j)\n",
    "        else:\n",
    "            break\n",
    "    block = [j for j in block_dict[block_ids[i]] if j < i]  # todo improve?\n",
    "    simmat_char_ngram.add_node(t, block)\n",
    "\n",
    "\n",
    "edit_sim = EditSim()\n",
    "simmat_edit = Simmat(sim_object=edit_sim)\n",
    "for i, t in enumerate(view[\"title\"]):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    block = []\n",
    "    for j in block_dict[block_ids[i]]:\n",
    "        if j < i:\n",
    "            block.append(j)\n",
    "        else:\n",
    "            break\n",
    "    block = [j for j in block_dict[block_ids[i]] if j < i]  # todo improve?\n",
    "    simmat_edit.add_node(t, block)\n",
    "\n",
    "\n",
    "tfidf_sim = TfidfSim(nodes=[i for i in view[\"title\"].values])\n",
    "simmat_tfidf = Simmat(sim_object=tfidf_sim)\n",
    "for i, t in enumerate(view[\"title\"]):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    block = []\n",
    "    for j in block_dict[block_ids[i]]:\n",
    "        if j < i:\n",
    "            block.append(j)\n",
    "        else:\n",
    "            break\n",
    "    block = [j for j in block_dict[block_ids[i]] if j < i]  # todo improve?\n",
    "    simmat_tfidf.add_node(t, block)\n",
    "\n",
    "\n",
    "partial_sim = EditPartialSim()\n",
    "simmat_partial = Simmat(sim_object=partial_sim)\n",
    "for i, t in enumerate(view[\"title\"]):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    block = []\n",
    "    for j in block_dict[block_ids[i]]:\n",
    "        if j < i:\n",
    "            block.append(j)\n",
    "        else:\n",
    "            break\n",
    "    block = [j for j in block_dict[block_ids[i]] if j < i]  # todo improve?\n",
    "    simmat_partial.add_node(t, block)\n",
    "\n",
    "\n",
    "partial_set_sim = EditSetSim()\n",
    "simmat_partial_set = Simmat(sim_object=partial_set_sim)\n",
    "for i, t in enumerate(view[\"title\"]):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    block = []\n",
    "    for j in block_dict[block_ids[i]]:\n",
    "        if j < i:\n",
    "            block.append(j)\n",
    "        else:\n",
    "            break\n",
    "    block = [j for j in block_dict[block_ids[i]] if j < i]  # todo improve?\n",
    "    simmat_partial_set.add_node(t, block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 1000 nodes and 7788 edges\n"
     ]
    }
   ],
   "source": [
    "use_clique = True\n",
    "simnet = SimNet(nodes=simmat_char_ngram.nodes, sim_mat=(0.7 * simmat_char_ngram.mat + 0.3 * simmat_edit.mat), edge_thresh=0.3, use_cliques=True)\n",
    "print(simnet.g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom pyvis.network import Network\\n\\n\\nnet = Network(notebook=True, cdn_resources='remote')\\nfor node in simnet.g.nodes:\\n    net.add_node(n_id=node, label=str(node), value=1)\\nfor edge in simnet.g.edges:\\n    net.add_edge(edge[0], edge[1])\\nnet.show('graph.html')\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from pyvis.network import Network\n",
    "\n",
    "\n",
    "net = Network(notebook=True, cdn_resources='remote')\n",
    "for node in simnet.g.nodes:\n",
    "    net.add_node(n_id=node, label=str(node), value=1)\n",
    "for edge in simnet.g.edges:\n",
    "    net.add_edge(edge[0], edge[1])\n",
    "net.show('graph.html')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairs</th>\n",
       "      <th>label</th>\n",
       "      <th>component</th>\n",
       "      <th>cn</th>\n",
       "      <th>pa</th>\n",
       "      <th>path</th>\n",
       "      <th>textsim_edit</th>\n",
       "      <th>textsim_char_ngram</th>\n",
       "      <th>clique</th>\n",
       "      <th>textsim_tfidf</th>\n",
       "      <th>textsim_partial</th>\n",
       "      <th>textsim_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[die schildkroten, die schildkröten - kribbel-...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.383929</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.136973</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.09</td>\n",
       "      <td>94.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[die schildkroten, die schildkröten]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.383929</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.131266</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.16</td>\n",
       "      <td>94.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[die schildkroten, joe tabu - diee schildkröten]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.383929</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.091315</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.00</td>\n",
       "      <td>88.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[die schildkroten, 03 03 für 'ne moment]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.383929</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.097022</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[die schildkroten, wolfgang niedecken - 03 für...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.383929</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.091315</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58379</th>\n",
       "      <td>[prélude no. 6 h-moll, op. 28: lento assai, so...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.051613</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58380</th>\n",
       "      <td>[prélude no. 6 h-moll, op. 28: lento assai, so...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.063524</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58381</th>\n",
       "      <td>[prélude no. 6 h-moll, op. 28: lento assai, fr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.059553</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.83</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58382</th>\n",
       "      <td>[prélude no. 6 h-moll, op. 28: lento assai, pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.051613</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.77</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58383</th>\n",
       "      <td>[prélude no. 6 h-moll, op. 28: lento assai, pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.067494</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.89</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58384 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   pairs  label  component  \\\n",
       "0      [die schildkroten, die schildkröten - kribbel-...      1   0.383929   \n",
       "1                   [die schildkroten, die schildkröten]      1   0.383929   \n",
       "2       [die schildkroten, joe tabu - diee schildkröten]      1   0.383929   \n",
       "3               [die schildkroten, 03 03 für 'ne moment]      0   0.383929   \n",
       "4      [die schildkroten, wolfgang niedecken - 03 für...      0   0.383929   \n",
       "...                                                  ...    ...        ...   \n",
       "58379  [prélude no. 6 h-moll, op. 28: lento assai, so...      0   0.607143   \n",
       "58380  [prélude no. 6 h-moll, op. 28: lento assai, so...      0   0.607143   \n",
       "58381  [prélude no. 6 h-moll, op. 28: lento assai, fr...      1   0.607143   \n",
       "58382  [prélude no. 6 h-moll, op. 28: lento assai, pr...      1   0.607143   \n",
       "58383  [prélude no. 6 h-moll, op. 28: lento assai, pr...      1   0.607143   \n",
       "\n",
       "             cn        pa      path  textsim_edit  textsim_char_ngram  \\\n",
       "0      0.620690  0.136973  0.714286          0.40                0.50   \n",
       "1      0.916667  0.131266  0.714286          0.06                0.79   \n",
       "2      0.560000  0.091315  0.714286          0.32                0.50   \n",
       "3      0.176471  0.097022  0.571429          0.72                0.00   \n",
       "4      0.181818  0.091315  0.571429          0.78                0.00   \n",
       "...         ...       ...       ...           ...                 ...   \n",
       "58379  0.318182  0.051613  0.571429          0.84                0.02   \n",
       "58380  0.280000  0.063524  0.571429          0.87                0.02   \n",
       "58381  0.631579  0.059553  0.714286          0.18                0.82   \n",
       "58382  0.705882  0.051613  0.714286          0.02                0.95   \n",
       "58383  0.571429  0.067494  0.714286          0.12                0.91   \n",
       "\n",
       "         clique  textsim_tfidf  textsim_partial  textsim_set  \n",
       "0      0.333333           0.09             94.0         64.0  \n",
       "1      1.000000           0.16             94.0         97.0  \n",
       "2      0.285714           0.00             88.0         73.0  \n",
       "3      0.000000           0.00             38.0         32.0  \n",
       "4      0.000000           0.00             38.0         20.0  \n",
       "...         ...            ...              ...          ...  \n",
       "58379  0.000000           0.00             24.0         24.0  \n",
       "58380  0.000000           0.00             24.0         24.0  \n",
       "58381  0.437500           0.83            100.0        100.0  \n",
       "58382  0.636364           0.77             98.0         99.0  \n",
       "58383  0.318182           0.89            100.0        100.0  \n",
       "\n",
       "[58384 rows x 12 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build dataset\n",
    "if use_clique:\n",
    "    clique = []\n",
    "component = []\n",
    "cn = []\n",
    "pa = []\n",
    "path = []\n",
    "pairs = []\n",
    "label = []\n",
    "textsim_char_ngram = []\n",
    "textsim_edit = []\n",
    "textsim_tfidf = []\n",
    "textsim_partial = []\n",
    "textsim_set = []\n",
    "\n",
    "label_dict = pd.Series(view[\"CID\"].values, index=view[\"title\"].values)\n",
    "nodes = view[\"title\"].values\n",
    "for i in range(len(nodes)):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    for j in block_dict[block_ids[i]]:\n",
    "        if i != j:\n",
    "            node_i = nodes[i]\n",
    "            node_j = nodes[j]\n",
    "            if use_clique:\n",
    "                clique.append(simnet.sim_clique_jaccard(node_i, node_j))\n",
    "            component.append(simnet.sim_component(node_i, node_j))\n",
    "            cn.append(simnet.sim_cn_jaccard(node_i, node_j, False))\n",
    "            pa.append(simnet.sim_preferential_attachment(node_i, node_j))\n",
    "            path.append(simnet.shortest_path(node_i, node_j))\n",
    "            pairs.append([node_i, node_j])\n",
    "            textsim_edit.append(simmat_edit.mat[i, j])\n",
    "            textsim_char_ngram.append(simmat_char_ngram.mat[i, j])\n",
    "            label.append(int(label_dict[node_i] == label_dict[node_j]))\n",
    "            textsim_tfidf.append(simmat_tfidf.mat[i, j])\n",
    "            textsim_partial.append(simmat_partial.mat[i, j])\n",
    "            textsim_set.append(simmat_partial_set.mat[i, j])\n",
    "if use_clique:\n",
    "    df = pd.DataFrame({\"pairs\": pairs, \"label\": label, \"component\": component, \"cn\": cn, \"pa\": pa, \"path\": path, \"textsim_edit\": textsim_edit, \"textsim_char_ngram\": textsim_char_ngram, \"clique\": clique, \"textsim_tfidf\": textsim_tfidf, \"textsim_partial\": textsim_partial, \"textsim_set\": textsim_set})\n",
    "else:\n",
    "    df = pd.DataFrame({\"pairs\": pairs, \"label\": label, \"component\": component, \"cn\": cn, \"pa\": pa, \"path\": path, \"textsim_edit\": textsim_edit, \"textsim_char_ngram\": textsim_char_ngram, \"textsim_tfidf\": textsim_tfidf, \"textsim_partial\": textsim_partial, \"textsim_set\": textsim_set})\n",
    "# impute & scale\n",
    "df[\"path\"] = 1 - df[\"path\"].fillna(df[\"path\"].max() + 1) / (df[\"path\"].max() + 1)\n",
    "df[\"pa\"] = df[\"pa\"] / df[\"pa\"].max()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9776951672862454\n",
      "0.8855218855218855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "\n",
    "# train test split, first 20% of nodes are treated as new at inference\n",
    "nodes_test = nodes[:int(len(nodes) * 0.2)]\n",
    "df[\"contains_node_test\"] = df[\"pairs\"].apply(lambda pair: (pair[0] in nodes_test) or (pair[1] in nodes_test))\n",
    "df_test = df[df[\"contains_node_test\"]].drop([\"contains_node_test\", \"pairs\"], axis=1)\n",
    "df_train = df[~df[\"contains_node_test\"]].drop([\"contains_node_test\", \"pairs\"], axis=1)\n",
    "x_train = df_train.drop(\"label\", axis=1)\n",
    "y_train = df_train[\"label\"]\n",
    "x_test = df_test.drop(\"label\", axis=1)\n",
    "y_test = df_test[\"label\"]\n",
    "\n",
    "# train / predict\n",
    "cls = RandomForestClassifier().fit(x_train, y_train)\n",
    "preds = cls.predict(x_test)\n",
    "print(recall_score(y_pred=preds, y_true=y_test))\n",
    "print(precision_score(y_pred=preds, y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>path</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>component</td>\n",
       "      <td>0.004551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cn</td>\n",
       "      <td>0.012193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pa</td>\n",
       "      <td>0.017236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>clique</td>\n",
       "      <td>0.018906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>textsim_edit</td>\n",
       "      <td>0.033962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>textsim_tfidf</td>\n",
       "      <td>0.164458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>textsim_partial</td>\n",
       "      <td>0.191459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>textsim_char_ngram</td>\n",
       "      <td>0.221813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>textsim_set</td>\n",
       "      <td>0.335169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  importance\n",
       "3                path    0.000252\n",
       "0           component    0.004551\n",
       "1                  cn    0.012193\n",
       "2                  pa    0.017236\n",
       "6              clique    0.018906\n",
       "4        textsim_edit    0.033962\n",
       "7       textsim_tfidf    0.164458\n",
       "8     textsim_partial    0.191459\n",
       "5  textsim_char_ngram    0.221813\n",
       "9         textsim_set    0.335169"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"feature\": x_train.columns, \"importance\": cls.feature_importances_}).sort_values(\"importance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
